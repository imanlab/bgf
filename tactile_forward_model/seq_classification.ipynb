{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierLSTM(nn.Module):\n",
    "    def __init__(self, device, context_frames):\n",
    "        super(ClassifierLSTM, self).__init__()\n",
    "        self.device = device\n",
    "        self.context_frames = context_frames\n",
    "        self.lstm = nn.LSTM(32, 200).to(device)  # tactile\n",
    "        self.fc1 = nn.Linear(200, 40).to(device)\n",
    "        self.fc2 = nn.Linear(40, 1).to(device)\n",
    "        self.tan_activation = nn.Tanh().to(device)\n",
    "        self.relu_activation = nn.ReLU().to(device)\n",
    "        self.softmax_activation = nn.Softmax(dim=1).to(device) #we don't use this because BCE loss in pytorch automatically applies the the Sigmoid activation\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, tactiles):\n",
    "        batch_size__ = tactiles.shape[1]\n",
    "        outputs = []\n",
    "        hidden = (torch.zeros(1, batch_size__, 200, device=torch.device('cuda')), torch.zeros(1, batch_size__, 200, device=torch.device('cuda')))\n",
    "        for index, sample_tactile_prediction in enumerate(tactiles):\n",
    "            lstm_out, self.hidden_lstm = self.lstm(sample_tactile_prediction.view(1, batch_size__, -1), hidden)\n",
    "            lstm_out_drop = self.dropout(lstm_out)\n",
    "            fc1_out = self.relu_activation(self.fc1(lstm_out_drop))\n",
    "            fc1_out_drop = self.dropout(fc1_out)\n",
    "            fc2_out = self.tan_activation(self.fc2(fc1_out_drop))\n",
    "            outputs.append(fc2_out.view(batch_size__, -1))\n",
    "\n",
    "\n",
    "        return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/kia/Kiyanoush/UoLincoln/Projects/Tactile_control/tactile_prediction/uninversal_trainer/ACTP/saved_models/model_29_07_2022_11_27_kins/test_results'\n",
    "files = sorted(glob.glob(data_dir + '/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is for Single Feature Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(files):\n",
    "    if index == 0:\n",
    "        t10_prediction_full = np.load(file + '/prediction_data.npy')[:, :, :32]\n",
    "        slip_data_full = np.load(file + '/slip_data.npy')\n",
    "    else:\n",
    "        t10_prediction = np.load(file + '/prediction_data.npy')[:, :, :32]\n",
    "        slip_data = np.load(file + '/slip_data.npy')\n",
    "        t10_prediction_full = np.concatenate((t10_prediction_full, t10_prediction), axis=0)\n",
    "        slip_data_full = np.concatenate((slip_data_full, slip_data), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is for Delta Feature Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(files):\n",
    "    if index == 0:\n",
    "        t10_prediction_full = np.load(file + '/prediction_data.npy')[:, :, :32]\n",
    "        slip_data_full = np.load(file + '/slip_data.npy')\n",
    "\n",
    "        t10_prediction_diff = np.diff(t10_prediction_full, axis=0)\n",
    "\n",
    "        t10_prediction_full = np.concatenate((t10_prediction_full[1:], t10_prediction_diff), axis=2)\n",
    "        slip_data_full = slip_data_full[1:]\n",
    "    else:\n",
    "        t10_prediction = np.load(file + '/prediction_data.npy')[:, :, :32]\n",
    "        slip_data = np.load(file + '/slip_data.npy')\n",
    "\n",
    "        t10_prediction_diff = np.diff(t10_prediction, axis=0)\n",
    "\n",
    "        t10_prediction = np.concatenate((t10_prediction[1:], t10_prediction_diff), axis=2)\n",
    "        slip_data = slip_data[1:]\n",
    "\n",
    "        t10_prediction_full = np.concatenate((t10_prediction_full, t10_prediction), axis=0)\n",
    "        slip_data_full = np.concatenate((slip_data_full, slip_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229760, 10, 32)\n",
      "(229760, 10)\n"
     ]
    }
   ],
   "source": [
    "print(t10_prediction_full.shape)\n",
    "print(slip_data_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detemporalize(X_seq):\n",
    "    x_2d = np.zeros((X_seq.shape[0] * X_seq.shape[1], X_seq.shape[2]))\n",
    "    for index, seq in enumerate(X_seq):\n",
    "        x_2d[10*index:10*(index+1)] = seq\n",
    "       \n",
    "    return x_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(t10_prediction_full, slip_data_full, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_2d = detemporalize(X_train)\n",
    "X_test_2d = detemporalize(X_test)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train_2d)\n",
    "X_train = scaler.transform(X_train_2d)\n",
    "X_test = scaler.transform(X_test_2d)\n",
    "dump(scaler, open('/home/kia/Kiyanoush/UoLincoln/Projects/Tactile_control/slip_classification/kins/classifier_standard_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalize(data_2d, seq_len):\n",
    "    x_3d = np.zeros((int(data_2d.shape[0] / seq_len), seq_len, data_2d.shape[1]))\n",
    "    for index in range(x_3d.shape[0]):\n",
    "        x_3d[index] = data_2d[10*index:10*(index+1)]\n",
    "    \n",
    "    return x_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = temporalize(X_train, 10)\n",
    "X_test = temporalize(X_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = TrainData(X_train, y_train)\n",
    "\n",
    "## test data    \n",
    "class TestData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "test_data = TestData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "ClassifierLSTM(\n",
      "  (lstm): LSTM(32, 200)\n",
      "  (fc1): Linear(in_features=200, out_features=40, bias=True)\n",
      "  (fc2): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (tan_activation): Tanh()\n",
      "  (relu_activation): ReLU()\n",
      "  (softmax_activation): Softmax(dim=1)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ClassifierLSTM(device, context_frames=10)\n",
    "model.to(device)\n",
    "weight = torch.Tensor([8]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195281\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/(y_test.shape[0]*y_test.shape[1])\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.96816 | Train Acc: 85.597 | Val Acc: 84.255 | saved model\n",
      "Epoch 002: | Loss: 0.91703 | Train Acc: 87.986 | Val Acc: 83.330 | \n",
      "Epoch 003: | Loss: 0.91359 | Train Acc: 88.209 | Val Acc: 84.739 | saved model\n",
      "Epoch 004: | Loss: 0.91090 | Train Acc: 88.401 | Val Acc: 84.719 | \n",
      "Epoch 005: | Loss: 0.90775 | Train Acc: 88.705 | Val Acc: 85.385 | saved model\n",
      "Epoch 006: | Loss: 0.90165 | Train Acc: 89.365 | Val Acc: 85.610 | saved model\n",
      "Epoch 007: | Loss: 0.89708 | Train Acc: 89.776 | Val Acc: 86.410 | saved model\n",
      "Epoch 008: | Loss: 0.89455 | Train Acc: 89.951 | Val Acc: 86.746 | saved model\n",
      "Epoch 009: | Loss: 0.89218 | Train Acc: 90.158 | Val Acc: 87.216 | saved model\n",
      "Epoch 010: | Loss: 0.89010 | Train Acc: 90.350 | Val Acc: 87.297 | saved model\n",
      "Epoch 011: | Loss: 0.88886 | Train Acc: 90.461 | Val Acc: 87.295 | \n",
      "Epoch 012: | Loss: 0.88771 | Train Acc: 90.584 | Val Acc: 87.297 | \n",
      "Epoch 013: | Loss: 0.88638 | Train Acc: 90.674 | Val Acc: 87.776 | saved model\n",
      "Epoch 014: | Loss: 0.88472 | Train Acc: 90.830 | Val Acc: 87.776 | \n",
      "Epoch 015: | Loss: 0.88373 | Train Acc: 90.943 | Val Acc: 87.423 | \n",
      "Epoch 016: | Loss: 0.88265 | Train Acc: 91.010 | Val Acc: 87.887 | saved model\n",
      "Epoch 017: | Loss: 0.88136 | Train Acc: 91.156 | Val Acc: 87.684 | \n",
      "Epoch 018: | Loss: 0.88062 | Train Acc: 91.240 | Val Acc: 88.043 | saved model\n",
      "Epoch 019: | Loss: 0.87946 | Train Acc: 91.300 | Val Acc: 88.465 | saved model\n",
      "Epoch 020: | Loss: 0.87835 | Train Acc: 91.412 | Val Acc: 88.163 | \n",
      "Epoch 021: | Loss: 0.87816 | Train Acc: 91.433 | Val Acc: 88.159 | \n",
      "Epoch 022: | Loss: 0.87752 | Train Acc: 91.487 | Val Acc: 88.833 | saved model\n",
      "Epoch 023: | Loss: 0.87471 | Train Acc: 91.845 | Val Acc: 88.640 | \n",
      "Epoch 024: | Loss: 0.87223 | Train Acc: 92.056 | Val Acc: 89.134 | saved model\n",
      "Epoch 025: | Loss: 0.87081 | Train Acc: 92.181 | Val Acc: 88.659 | \n",
      "Epoch 026: | Loss: 0.87003 | Train Acc: 92.251 | Val Acc: 89.467 | saved model\n",
      "Epoch 027: | Loss: 0.86869 | Train Acc: 92.382 | Val Acc: 89.405 | \n",
      "Epoch 028: | Loss: 0.86825 | Train Acc: 92.418 | Val Acc: 89.785 | saved model\n",
      "Epoch 029: | Loss: 0.86772 | Train Acc: 92.478 | Val Acc: 89.556 | \n",
      "Epoch 030: | Loss: 0.86630 | Train Acc: 92.724 | Val Acc: 89.409 | \n",
      "Epoch 031: | Loss: 0.86578 | Train Acc: 92.850 | Val Acc: 89.502 | \n",
      "Epoch 032: | Loss: 0.86466 | Train Acc: 92.988 | Val Acc: 90.303 | saved model\n",
      "Epoch 033: | Loss: 0.86362 | Train Acc: 93.084 | Val Acc: 89.702 | \n",
      "Epoch 034: | Loss: 0.86276 | Train Acc: 93.107 | Val Acc: 90.219 | \n",
      "Epoch 035: | Loss: 0.86209 | Train Acc: 93.165 | Val Acc: 89.971 | \n",
      "Epoch 036: | Loss: 0.86112 | Train Acc: 93.264 | Val Acc: 89.945 | \n",
      "Epoch 037: | Loss: 0.86073 | Train Acc: 93.276 | Val Acc: 90.719 | saved model\n",
      "Epoch 038: | Loss: 0.86052 | Train Acc: 93.304 | Val Acc: 90.214 | \n",
      "Epoch 039: | Loss: 0.86059 | Train Acc: 93.292 | Val Acc: 90.535 | \n",
      "Epoch 040: | Loss: 0.85935 | Train Acc: 93.362 | Val Acc: 90.087 | \n",
      "Epoch 041: | Loss: 0.85944 | Train Acc: 93.390 | Val Acc: 90.061 | \n",
      "Epoch 042: | Loss: 0.85893 | Train Acc: 93.406 | Val Acc: 90.172 | \n",
      "Epoch 043: | Loss: 0.85876 | Train Acc: 93.412 | Val Acc: 90.175 | \n",
      "Epoch 044: | Loss: 0.85868 | Train Acc: 93.477 | Val Acc: 90.471 | \n",
      "Epoch 045: | Loss: 0.85852 | Train Acc: 93.472 | Val Acc: 90.869 | saved model\n",
      "Epoch 046: | Loss: 0.85732 | Train Acc: 93.541 | Val Acc: 90.537 | \n",
      "Epoch 047: | Loss: 0.85770 | Train Acc: 93.524 | Val Acc: 90.490 | \n",
      "Epoch 048: | Loss: 0.85729 | Train Acc: 93.514 | Val Acc: 90.770 | \n",
      "Epoch 049: | Loss: 0.85679 | Train Acc: 93.574 | Val Acc: 90.457 | \n",
      "Epoch 050: | Loss: 0.85684 | Train Acc: 93.568 | Val Acc: 90.651 | \n",
      "Epoch 051: | Loss: 0.85674 | Train Acc: 93.553 | Val Acc: 90.390 | \n",
      "Epoch 052: | Loss: 0.85624 | Train Acc: 93.597 | Val Acc: 90.503 | \n",
      "Epoch 053: | Loss: 0.85614 | Train Acc: 93.623 | Val Acc: 90.860 | \n",
      "Epoch 054: | Loss: 0.85598 | Train Acc: 93.630 | Val Acc: 90.519 | \n",
      "Epoch 055: | Loss: 0.85545 | Train Acc: 93.659 | Val Acc: 90.885 | saved model\n",
      "Epoch 056: | Loss: 0.85510 | Train Acc: 93.699 | Val Acc: 90.876 | \n",
      "Epoch 057: | Loss: 0.85538 | Train Acc: 93.666 | Val Acc: 90.647 | \n",
      "Epoch 058: | Loss: 0.85536 | Train Acc: 93.689 | Val Acc: 90.654 | \n",
      "Epoch 059: | Loss: 0.85509 | Train Acc: 93.689 | Val Acc: 90.927 | saved model\n",
      "Epoch 060: | Loss: 0.85487 | Train Acc: 93.716 | Val Acc: 90.564 | \n",
      "Epoch 061: | Loss: 0.85464 | Train Acc: 93.739 | Val Acc: 91.059 | saved model\n",
      "Epoch 062: | Loss: 0.85460 | Train Acc: 93.773 | Val Acc: 90.728 | \n",
      "Epoch 063: | Loss: 0.85423 | Train Acc: 93.771 | Val Acc: 90.954 | \n",
      "Epoch 064: | Loss: 0.85411 | Train Acc: 93.803 | Val Acc: 91.115 | saved model\n",
      "Epoch 065: | Loss: 0.85419 | Train Acc: 93.792 | Val Acc: 91.369 | saved model\n",
      "Epoch 066: | Loss: 0.85383 | Train Acc: 93.833 | Val Acc: 90.843 | \n",
      "Epoch 067: | Loss: 0.85369 | Train Acc: 93.845 | Val Acc: 91.085 | \n",
      "Epoch 068: | Loss: 0.85379 | Train Acc: 93.812 | Val Acc: 91.189 | \n",
      "Epoch 069: | Loss: 0.85363 | Train Acc: 93.814 | Val Acc: 91.250 | \n",
      "Epoch 070: | Loss: 0.85329 | Train Acc: 93.880 | Val Acc: 90.856 | \n"
     ]
    }
   ],
   "source": [
    "epochs = 70\n",
    "score_file = np.zeros((epochs, 2))\n",
    "best_val_acc = 0.0\n",
    "for e in range(1, epochs+1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_save = \"\"\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.type(torch.FloatTensor)\n",
    "        y_batch = y_batch.type(torch.FloatTensor)\n",
    "        \n",
    "        X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        y_pred = y_pred.permute(1, 0, 2).view(128, 10)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    score_file[e-1, 0] = epoch_acc/len(train_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred_list = []\n",
    "        model.eval()\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.type(torch.FloatTensor)\n",
    "            X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "            \n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "\n",
    "            y_test_pred = y_test_pred.permute(1, 0, 2).view(1, 10)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "    \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    \n",
    "    val_acc = accuracy_score(y_test, y_pred_list) * 100\n",
    "\n",
    "    score_file[e-1, 1] = val_acc\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model, '/home/kia/Kiyanoush/UoLincoln/Projects/Tactile_control/slip_classification/kins/classifier_lstm')\n",
    "        model_save = \"saved model\"\n",
    "\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Train Acc: {epoch_acc/len(train_loader):.3f} | Val Acc: {val_acc:.3f} | {model_save}')\n",
    "\n",
    "np.save('/home/kia/Kiyanoush/UoLincoln/Projects/Tactile_control/slip_classification/Long_horizon/scores.npy', score_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierLSTM(\n",
       "  (lstm): LSTM(32, 200)\n",
       "  (fc1): Linear(in_features=200, out_features=40, bias=True)\n",
       "  (fc2): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (tan_activation): Tanh()\n",
       "  (relu_activation): ReLU()\n",
       "  (softmax_activation): Softmax(dim=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('/home/kia/Kiyanoush/UoLincoln/Projects/Tactile_control/slip_classification/Class_sequence/single_feature/single_feature_classifier_lstm').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.type(torch.FloatTensor)\n",
    "        X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = y_test_pred.permute(1, 0, 2).view(1, 50)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2577\n",
      "           1       0.96      0.97      0.97      2624\n",
      "           2       0.96      0.97      0.97      2687\n",
      "           3       0.96      0.97      0.97      2723\n",
      "           4       0.98      0.97      0.97      2778\n",
      "           5       0.97      0.98      0.98      2820\n",
      "           6       0.98      0.98      0.98      2877\n",
      "           7       0.97      0.98      0.98      2925\n",
      "           8       0.98      0.98      0.98      2979\n",
      "           9       0.98      0.97      0.98      3023\n",
      "          10       0.98      0.97      0.98      3085\n",
      "          11       0.98      0.98      0.98      3142\n",
      "          12       0.98      0.98      0.98      3219\n",
      "          13       0.98      0.98      0.98      3281\n",
      "          14       0.98      0.97      0.97      3353\n",
      "          15       0.98      0.97      0.97      3417\n",
      "          16       0.98      0.97      0.97      3460\n",
      "          17       0.98      0.97      0.97      3523\n",
      "          18       0.98      0.97      0.97      3564\n",
      "          19       0.98      0.97      0.98      3633\n",
      "          20       0.98      0.97      0.98      3690\n",
      "          21       0.98      0.97      0.98      3750\n",
      "          22       0.98      0.97      0.98      3794\n",
      "          23       0.98      0.97      0.98      3850\n",
      "          24       0.98      0.97      0.97      3896\n",
      "          25       0.98      0.97      0.97      3913\n",
      "          26       0.98      0.97      0.97      3955\n",
      "          27       0.97      0.97      0.97      3987\n",
      "          28       0.97      0.97      0.97      4004\n",
      "          29       0.97      0.96      0.97      4043\n",
      "          30       0.97      0.96      0.97      4091\n",
      "          31       0.97      0.96      0.97      4118\n",
      "          32       0.97      0.96      0.96      4145\n",
      "          33       0.97      0.96      0.96      4177\n",
      "          34       0.97      0.96      0.96      4178\n",
      "          35       0.96      0.96      0.96      4203\n",
      "          36       0.97      0.96      0.96      4234\n",
      "          37       0.97      0.96      0.96      4276\n",
      "          38       0.96      0.96      0.96      4305\n",
      "          39       0.96      0.96      0.96      4317\n",
      "          40       0.96      0.96      0.96      4327\n",
      "          41       0.96      0.96      0.96      4334\n",
      "          42       0.96      0.96      0.96      4359\n",
      "          43       0.96      0.96      0.96      4386\n",
      "          44       0.96      0.96      0.96      4437\n",
      "          45       0.96      0.96      0.96      4475\n",
      "          46       0.96      0.96      0.96      4498\n",
      "          47       0.96      0.96      0.96      4525\n",
      "          48       0.96      0.96      0.96      4551\n",
      "          49       0.96      0.96      0.96      4576\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    187084\n",
      "   macro avg       0.97      0.97      0.97    187084\n",
      "weighted avg       0.97      0.97      0.97    187084\n",
      " samples avg       0.20      0.20      0.20    187084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kia/miniconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kia/miniconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = np.asarray(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 32.09375, 'Predicted class')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test[:, -1], y_pred_list[:, -1])\n",
    "LABELS = [\"non_slip\",\"slip\"]\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "# plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025365114212036133\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "count = 0\n",
    "t1 = time.time()\n",
    "for X_batch, y_batch in train_loader:\n",
    "    X_batch = X_batch.type(torch.FloatTensor)\n",
    "    X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "    \n",
    "    X_batch = X_batch.to(device)\n",
    "    y_test_pred = model(X_batch)\n",
    "    y_test_pred = torch.sigmoid(y_test_pred)\n",
    "    y_pred_tag = torch.round(y_test_pred)\n",
    "    y_pred_list.append(y_pred_tag.cpu().detach().numpy())\n",
    "    t2 = time.time()\n",
    "    break\n",
    "\n",
    "print(t2-t1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53fcb633c9691f82046febe19aeee415856832757c230a8d8b4a8d6fbeb0243"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
